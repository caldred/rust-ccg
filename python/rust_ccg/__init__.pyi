"""Type stubs for rust_ccg."""

from typing import List, Tuple, Optional, Callable, Iterator
import numpy as np
from numpy.typing import NDArray

# Core types

class PlayerId:
    """Player identifier (0-255)."""
    def __init__(self, id: int) -> None: ...
    def index(self) -> int: ...
    @property
    def id(self) -> int: ...
    def __repr__(self) -> str: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...

class TemplateId:
    """Action template identifier."""
    def __init__(self, id: int) -> None: ...
    @property
    def id(self) -> int: ...
    def __repr__(self) -> str: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...

class Action:
    """Game action with template ID and targets."""
    def __init__(self, template_id: int) -> None: ...
    @property
    def template_id(self) -> int: ...
    def pointer_count(self) -> int: ...
    def __repr__(self) -> str: ...
    def __eq__(self, other: object) -> bool: ...
    def __hash__(self) -> int: ...

# Neural network types

class EncodedState:
    """Tensor representation of game state."""
    def __init__(self, tensor: List[float], shape: List[int]) -> None: ...
    @staticmethod
    def zeros(shape: List[int]) -> EncodedState: ...
    @property
    def tensor(self) -> List[float]: ...
    @property
    def shape(self) -> List[int]: ...
    def __len__(self) -> int: ...
    def __repr__(self) -> str: ...
    def to_numpy(self) -> NDArray[np.float32]: ...
    def get(self, index: int) -> Optional[float]: ...
    def set(self, index: int, value: float) -> None: ...

class PolicyValueNetwork:
    """Wrapper for Python neural networks.

    The callback should accept an EncodedState and return:
    - policy: List[float] of length action_space_size
    - values: List[float] of length player_count

    If the callback raises an exception, a fallback uniform policy
    and zero values will be returned instead of crashing.
    """
    def __init__(
        self,
        callback: Callable[[EncodedState], Tuple[List[float], List[float]]],
        action_space_size: int,
        player_count: int = 2,
    ) -> None: ...
    def predict(self, encoded: EncodedState) -> Tuple[List[float], List[float]]: ...
    @property
    def action_space_size(self) -> int: ...
    @property
    def player_count(self) -> int: ...

class UniformPolicy:
    """Baseline uniform random policy."""
    def __init__(self, action_space_size: int, player_count: int = 2) -> None: ...
    def predict(self, encoded: EncodedState) -> Tuple[List[float], List[float]]: ...

class SimpleEncoder:
    """Basic state encoder for SimpleGame."""
    def __init__(self, player_count: int = 2, features_per_player: int = 5) -> None: ...
    def output_shape(self) -> List[int]: ...
    @property
    def player_count(self) -> int: ...
    def encode(self, perspective: PlayerId) -> EncodedState: ...

# Training types

class Step:
    """Single game step with state, action, and MCTS policy."""
    @property
    def encoded_state(self) -> EncodedState: ...
    @property
    def action_probs(self) -> List[Tuple[Action, float]]: ...
    @property
    def action_taken(self) -> Action: ...
    @property
    def player(self) -> PlayerId: ...
    @property
    def move_number(self) -> int: ...
    def __repr__(self) -> str: ...

class Trajectory:
    """Complete game record with outcome."""
    @property
    def steps(self) -> List[Step]: ...
    @property
    def outcome(self) -> List[Tuple[int, float]]: ...
    @property
    def game_length(self) -> int: ...
    @property
    def seed(self) -> int: ...
    def __len__(self) -> int: ...
    def __repr__(self) -> str: ...
    def player_steps(self, player: PlayerId) -> List[Step]: ...
    def to_training_samples(self) -> List[TrainingSample]: ...

class TrainingSample:
    """Training example (state, policy, value)."""
    @property
    def state(self) -> EncodedState: ...
    @property
    def policy(self) -> List[float]: ...
    @property
    def value(self) -> float: ...
    @property
    def player(self) -> PlayerId: ...
    def __repr__(self) -> str: ...
    def state_numpy(self) -> NDArray[np.float32]: ...
    def policy_numpy(self) -> NDArray[np.float32]: ...

class ExperienceBuffer:
    """FIFO buffer for trajectories."""
    def __init__(self, max_trajectories: int) -> None: ...
    def push(self, trajectory: Trajectory) -> None: ...
    def __len__(self) -> int: ...
    def __iter__(self) -> Iterator[Trajectory]: ...
    def __repr__(self) -> str: ...
    def is_empty(self) -> bool: ...
    @property
    def capacity(self) -> int: ...
    def clear(self) -> None: ...
    def to_training_samples(self) -> List[TrainingSample]: ...
    def sample_batch(self, batch_size: int, seed: int) -> List[TrainingSample]: ...
    def to_numpy_batch(self) -> Tuple[
        NDArray[np.float32],  # states: [N, state_dim]
        NDArray[np.float32],  # policies: [N, action_dim]
        NDArray[np.float32],  # values: [N]
    ]: ...

# Self-play

class SelfPlayConfig:
    """Configuration for MCTS self-play."""
    def __init__(
        self,
        mcts_iterations: int = 800,
        temperature: float = 1.0,
        temperature_threshold: int = 30,
        max_moves: int = 500,
        exploration_constant: float = 1.414,
    ) -> None: ...
    @property
    def mcts_iterations(self) -> int: ...
    @property
    def temperature(self) -> float: ...
    @property
    def temperature_threshold(self) -> int: ...
    @property
    def max_moves(self) -> int: ...
    @property
    def exploration_constant(self) -> float: ...
    def __repr__(self) -> str: ...

class SimpleGameWorker:
    """Self-play worker for SimpleGame."""
    def __init__(
        self,
        player_count: int,
        config: SelfPlayConfig,
        starting_life: int = 20,
        starting_hand_size: int = 5,
        cards_per_player: int = 10,
    ) -> None: ...
    def play_game(self, seed: int) -> Trajectory: ...
    def play_game_with_network(self, seed: int, network: PolicyValueNetwork) -> Trajectory: ...
    def play_games(self, count: int, base_seed: int) -> List[Trajectory]: ...
    def play_games_with_network(
        self, count: int, base_seed: int, network: PolicyValueNetwork
    ) -> List[Trajectory]: ...
    def __repr__(self) -> str: ...

# Games

class SimpleGame:
    """Simple card game for testing."""
    def __init__(
        self,
        player_count: int = 2,
        starting_life: int = 20,
        starting_hand_size: int = 5,
        cards_per_player: int = 10,
        seed: int = 42,
    ) -> None: ...
    def legal_actions(self) -> List[Action]: ...
    def apply_action(self, action: Action) -> None: ...
    def is_terminal(self) -> Optional[PlayerId]: ...
    def has_winner(self) -> bool: ...
    @property
    def active_player(self) -> PlayerId: ...
    @property
    def turn_number(self) -> int: ...
    @property
    def player_count(self) -> int: ...
    def get_life(self, player: PlayerId) -> int: ...
    def get_hand_size(self, player: PlayerId) -> int: ...
    def copy(self) -> SimpleGame: ...
    def __repr__(self) -> str: ...
